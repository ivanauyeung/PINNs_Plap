# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
# SPDX-License-Identifier: Apache-2.0
#
# p-Laplacian: Aronsson Example (Homogeneous Dirichlet)
# Configuration for PhysicsNeMo-sym
#
# Problem:
#   Domain: [-1, 1] × [-1, 1]
#   BC: u = |x|^(4/3) - |y|^(4/3) on ∂Ω
#   PDE: Δ_p u = 0 (homogeneous p-Laplacian)
#   Parameter: p ∈ [2, 100]

defaults:
  - physicsnemo_default
  - arch:
      - fully_connected
  - scheduler: tf_exponential_lr
  - optimizer: adam
  - loss: relobralo
  - _self_

# Custom settings
custom:
  # p parameter range for training
  p_min: 2.0
  p_max: 10.0
  # Validation p value (high p ~ infinity-Laplacian)
  p_validation: 10.0

# Network directory for outputs
save_filetypes: vtk

# Scheduler settings
scheduler:
  decay_rate: 0.95
  decay_steps: 2000

# ReLoBRaLo loss aggregator settings
# Reference: "Multi-Objective Loss Balancing for Physics-Informed Deep Learning"
loss:
  alpha: 0.95
  beta: 0.99
  tau: 1.0
  eps: 1.0e-08

# Training configuration
training:
  max_steps: 50000
  rec_results_freq: 2000
  rec_validation_freq: 2000
  rec_inference_freq: 2000
  rec_monitor_freq: 200
  rec_constraint_freq: 2000
  save_network_freq: 5000
  print_stats_freq: 200
  summary_freq: 200

# Batch sizes
batch_size:
  BC: 512
  interior: 2000

# Network architecture - larger network for parameterized problem
arch:
  fully_connected:
    layer_size: 64
    nr_layers: 5

